{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0cd6385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Rimsha\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "# from spellchecker import SpellChecker\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# spell = SpellChecker()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bcdee711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Removing urls\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    text = url_pattern.sub('', text)\n",
    "    # Removing special characters, punctuations, emojis and symbols\n",
    "    text = re.sub(r'[^\\w\\s\\d]|[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00026000-\\U00026FFF]', '', text)\n",
    "    # Removing email address \n",
    "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '', text)\n",
    "    # Removing newline\n",
    "    text = text.replace('\\n', ' ')\n",
    "    # Removing hashtags\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    # Removing whitespace and extra spaces\n",
    "    text = ' '.join(text.split())\n",
    "    # Removing stopwords\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    # spelling correction\n",
    "#     corrected_tokens = [spell.correction(word) for word in filtered_tokens]\n",
    "    # lemmatization\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    text = ' '.join(lemmatized_tokens)\n",
    "    return text\n",
    "\n",
    "class CategoriesClassifier:\n",
    "    def __init__(self, df_train, df_test, df_validation):\n",
    "        self.df_train = df_train.copy()\n",
    "        self.df_test = df_test.copy()\n",
    "        self.df_validation = df_validation.copy()\n",
    "        self.data_type = {\n",
    "            'train': self.df_train,\n",
    "            'test': self.df_test,\n",
    "            'validation': self.df_validation,\n",
    "        }\n",
    "        \n",
    "    def preprocess_text(self, cols):\n",
    "        for v in self.data_type.values():\n",
    "            for c in cols:\n",
    "                v[c] = v[c].apply(preprocess_text)\n",
    "            \n",
    "    def visualize_top_categories(self, data, level, top_n=10):\n",
    "        df = self.data_type.get(data)\n",
    "        top_categories = df[level].value_counts().nlargest(top_n)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(x=top_categories.values, y=top_categories.index, palette='viridis')\n",
    "        plt.title(f'Top {top_n} Categories in {level}')\n",
    "        plt.xlabel('Number of Products')\n",
    "        plt.ylabel('Category')\n",
    "        plt.show()\n",
    "        \n",
    "    def visualize_wordcloud(self, data):\n",
    "        df = self.data_type.get(data)\n",
    "        all_descriptions = ' '.join(df['Description'])\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_descriptions)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title('Word Cloud of Product Descriptions\\n')\n",
    "        plt.show()\n",
    "        \n",
    "    def visualize_description_length(self, data):\n",
    "        df = self.data_type.get(data)\n",
    "        df['Description_Length'] = df['Description'].apply(len)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.histplot(df['Description_Length'], bins=20, kde=True)\n",
    "        plt.xlabel('Description Length')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Description Length Distribution')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c432ec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_json('Data/train_data.json', lines=True)\n",
    "df_test = pd.read_json('Data/test_data.json', lines=True)\n",
    "df_validation = pd.read_json('Data/validation_data.json', lines=True)\n",
    "\n",
    "cls = CategoriesClassifier(df_train, df_test, df_validation)\n",
    "cls.preprocess_text(['Description', 'Name', 'CategoryText'])\n",
    "# cls.visualize_top_categories('train', 'lvl1')\n",
    "# cls.visualize_top_categories('train', 'lvl2')\n",
    "# cls.visualize_top_categories('train', 'lvl3')\n",
    "# cls.visualize_wordcloud('train')\n",
    "# cls.visualize_description_length('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e067d004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>CategoryText</th>\n",
       "      <th>URL</th>\n",
       "      <th>lvl1</th>\n",
       "      <th>lvl2</th>\n",
       "      <th>lvl3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>549</td>\n",
       "      <td>sterling silver angel charm</td>\n",
       "      <td>little angel charm heavenly</td>\n",
       "      <td>product</td>\n",
       "      <td>http://www.thecharmworks.com/product/CW-UA/Ste...</td>\n",
       "      <td>64000000_Personal Accessories</td>\n",
       "      <td>64010000_Personal Accessories</td>\n",
       "      <td>64010100_Jewellery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5664</td>\n",
       "      <td>hp pavilion 23xi 5840 cm 23 ip monitor</td>\n",
       "      <td>share photo video game everyone room experienc...</td>\n",
       "      <td>product</td>\n",
       "      <td>http://store.hp.com/UKStore/Merch/Product.aspx...</td>\n",
       "      <td>65000000_Computing</td>\n",
       "      <td>65010000_Computers/Video Games</td>\n",
       "      <td>65010700_Computer/Video Game Peripherals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3307</td>\n",
       "      <td>east carolina pirate lady personalized basketb...</td>\n",
       "      <td>feel like bona fide member east carolina pirat...</td>\n",
       "      <td>east carolina pirate east carolina pirate lady...</td>\n",
       "      <td>http://eastcarolina.teamfanshop.com/COLLEGE_Ea...</td>\n",
       "      <td>67000000_Clothing</td>\n",
       "      <td>67010000_Clothing</td>\n",
       "      <td>67010800_Upper Body Wear/Tops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4609</td>\n",
       "      <td>tekonsha 90195 p3 electric brake control 14 tr...</td>\n",
       "      <td>receive free shipping item enter coupon code f...</td>\n",
       "      <td>vehicle part vehicle part accessory</td>\n",
       "      <td>http://www.anythingtruck.com/product/755-90195...</td>\n",
       "      <td>77000000_Automotive</td>\n",
       "      <td>77010000_Automotive Accessories and Maintenance</td>\n",
       "      <td>77011200_Automotive Maintenance/Repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7822</td>\n",
       "      <td>rnxv wifly module wire antenna</td>\n",
       "      <td>description rnxv module roving network certifi...</td>\n",
       "      <td>home wireless wifi rnxv wifly module wire antenna</td>\n",
       "      <td>http://www.karlssonrobotics.com/cart/rn-xv-wif...</td>\n",
       "      <td>78000000_Electrical Supplies</td>\n",
       "      <td>78050000_Electronic Communication Components</td>\n",
       "      <td>78050100_Electronic Communication Components</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007</th>\n",
       "      <td>10329</td>\n",
       "      <td>men washington capital reebok striped scarf</td>\n",
       "      <td>get game season washington capital striped sca...</td>\n",
       "      <td></td>\n",
       "      <td>http://shop.nhl.com/Men_Mothers_Day</td>\n",
       "      <td>67000000_Clothing</td>\n",
       "      <td>67010000_Clothing</td>\n",
       "      <td>67010100_Clothing Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10008</th>\n",
       "      <td>5191</td>\n",
       "      <td>new york yankee lady stripe cami tank navy blue</td>\n",
       "      <td>warm weather day want stay cool enjoy new york...</td>\n",
       "      <td>mlb new york yankee new york yankee tshirts ne...</td>\n",
       "      <td>http://yahoosports.teamfanshop.com/MLB_Basebal...</td>\n",
       "      <td>67000000_Clothing</td>\n",
       "      <td>67010000_Clothing</td>\n",
       "      <td>67010800_Upper Body Wear/Tops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>5390</td>\n",
       "      <td>men uconn husky navy blue arch tshirt</td>\n",
       "      <td>celebrate fandom uconn husky arch tshirt featu...</td>\n",
       "      <td>uconn husky uconn husky tshirts</td>\n",
       "      <td>http://shop.uconnhuskies.com/COLLEGE_UCONN_Hus...</td>\n",
       "      <td>67000000_Clothing</td>\n",
       "      <td>67010000_Clothing</td>\n",
       "      <td>67010800_Upper Body Wear/Tops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>860</td>\n",
       "      <td>sony ericsson xperia arc lt18i</td>\n",
       "      <td>product feature 3g wifi hdmi14 ghz processor51...</td>\n",
       "      <td>mobile</td>\n",
       "      <td>http://www.smartprix.com/mobiles/sony_ericsson...</td>\n",
       "      <td>66000000_Communications</td>\n",
       "      <td>66010000_Communications</td>\n",
       "      <td>66010300_Mobile Communication Devices/Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>7270</td>\n",
       "      <td>riviera toe ring</td>\n",
       "      <td>riviera classy sapphire clear crystal eternity...</td>\n",
       "      <td>toe ring toe ring sized</td>\n",
       "      <td>http://www.sassytoe.com/Toe_Rings_Anklets-Toe_...</td>\n",
       "      <td>64000000_Personal Accessories</td>\n",
       "      <td>64010000_Personal Accessories</td>\n",
       "      <td>64010100_Jewellery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10012 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                               Name  \\\n",
       "0        549                        sterling silver angel charm   \n",
       "1       5664             hp pavilion 23xi 5840 cm 23 ip monitor   \n",
       "2       3307  east carolina pirate lady personalized basketb...   \n",
       "3       4609  tekonsha 90195 p3 electric brake control 14 tr...   \n",
       "4       7822                     rnxv wifly module wire antenna   \n",
       "...      ...                                                ...   \n",
       "10007  10329        men washington capital reebok striped scarf   \n",
       "10008   5191    new york yankee lady stripe cami tank navy blue   \n",
       "10009   5390              men uconn husky navy blue arch tshirt   \n",
       "10010    860                     sony ericsson xperia arc lt18i   \n",
       "10011   7270                                   riviera toe ring   \n",
       "\n",
       "                                             Description  \\\n",
       "0                            little angel charm heavenly   \n",
       "1      share photo video game everyone room experienc...   \n",
       "2      feel like bona fide member east carolina pirat...   \n",
       "3      receive free shipping item enter coupon code f...   \n",
       "4      description rnxv module roving network certifi...   \n",
       "...                                                  ...   \n",
       "10007  get game season washington capital striped sca...   \n",
       "10008  warm weather day want stay cool enjoy new york...   \n",
       "10009  celebrate fandom uconn husky arch tshirt featu...   \n",
       "10010  product feature 3g wifi hdmi14 ghz processor51...   \n",
       "10011  riviera classy sapphire clear crystal eternity...   \n",
       "\n",
       "                                            CategoryText  \\\n",
       "0                                                product   \n",
       "1                                                product   \n",
       "2      east carolina pirate east carolina pirate lady...   \n",
       "3                    vehicle part vehicle part accessory   \n",
       "4      home wireless wifi rnxv wifly module wire antenna   \n",
       "...                                                  ...   \n",
       "10007                                                      \n",
       "10008  mlb new york yankee new york yankee tshirts ne...   \n",
       "10009                    uconn husky uconn husky tshirts   \n",
       "10010                                             mobile   \n",
       "10011                            toe ring toe ring sized   \n",
       "\n",
       "                                                     URL  \\\n",
       "0      http://www.thecharmworks.com/product/CW-UA/Ste...   \n",
       "1      http://store.hp.com/UKStore/Merch/Product.aspx...   \n",
       "2      http://eastcarolina.teamfanshop.com/COLLEGE_Ea...   \n",
       "3      http://www.anythingtruck.com/product/755-90195...   \n",
       "4      http://www.karlssonrobotics.com/cart/rn-xv-wif...   \n",
       "...                                                  ...   \n",
       "10007                http://shop.nhl.com/Men_Mothers_Day   \n",
       "10008  http://yahoosports.teamfanshop.com/MLB_Basebal...   \n",
       "10009  http://shop.uconnhuskies.com/COLLEGE_UCONN_Hus...   \n",
       "10010  http://www.smartprix.com/mobiles/sony_ericsson...   \n",
       "10011  http://www.sassytoe.com/Toe_Rings_Anklets-Toe_...   \n",
       "\n",
       "                                lvl1  \\\n",
       "0      64000000_Personal Accessories   \n",
       "1                 65000000_Computing   \n",
       "2                  67000000_Clothing   \n",
       "3                77000000_Automotive   \n",
       "4       78000000_Electrical Supplies   \n",
       "...                              ...   \n",
       "10007              67000000_Clothing   \n",
       "10008              67000000_Clothing   \n",
       "10009              67000000_Clothing   \n",
       "10010        66000000_Communications   \n",
       "10011  64000000_Personal Accessories   \n",
       "\n",
       "                                                  lvl2  \\\n",
       "0                        64010000_Personal Accessories   \n",
       "1                       65010000_Computers/Video Games   \n",
       "2                                    67010000_Clothing   \n",
       "3      77010000_Automotive Accessories and Maintenance   \n",
       "4         78050000_Electronic Communication Components   \n",
       "...                                                ...   \n",
       "10007                                67010000_Clothing   \n",
       "10008                                67010000_Clothing   \n",
       "10009                                67010000_Clothing   \n",
       "10010                          66010000_Communications   \n",
       "10011                    64010000_Personal Accessories   \n",
       "\n",
       "                                                 lvl3  \n",
       "0                                  64010100_Jewellery  \n",
       "1            65010700_Computer/Video Game Peripherals  \n",
       "2                       67010800_Upper Body Wear/Tops  \n",
       "3              77011200_Automotive Maintenance/Repair  \n",
       "4        78050100_Electronic Communication Components  \n",
       "...                                               ...  \n",
       "10007                   67010100_Clothing Accessories  \n",
       "10008                   67010800_Upper Body Wear/Tops  \n",
       "10009                   67010800_Upper Body Wear/Tops  \n",
       "10010  66010300_Mobile Communication Devices/Services  \n",
       "10011                              64010100_Jewellery  \n",
       "\n",
       "[10012 rows x 8 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e441298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem import WordNetLemmatizer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# import unicodedata\n",
    "\n",
    "# from spellchecker import SpellChecker\n",
    "\n",
    "# def correct_spelling(text):\n",
    "#     # Correct spelling errors using a spell checker\n",
    "#     spell = SpellChecker()\n",
    "#     tokens = word_tokenize(text)\n",
    "#     corrected_tokens = [spell.correction(word) for word in tokens]\n",
    "#     return ' '.join(corrected_tokens)\n",
    "\n",
    "# def remove_html_tags(text):\n",
    "#     # Remove HTML tags from the text\n",
    "#     cleaner = re.compile('<.*?>')\n",
    "#     cleaned_text = re.sub(cleaner, '', text)\n",
    "#     return cleaned_text\n",
    "\n",
    "# def remove_stopwords(text):\n",
    "#     # Remove stopwords using spaCy (which has a more comprehensive stopwords list)\n",
    "#     doc = nlp(text)\n",
    "#     tokens = [token.text for token in doc if not token.is_stop]\n",
    "#     return ' '.join(tokens)\n",
    "\n",
    "\n",
    "# import string\n",
    "\n",
    "# def remove_punctuation(text):\n",
    "#     # Remove punctuation\n",
    "#     translator = str.maketrans('', '', string.punctuation)\n",
    "#     return text.translate(translator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "840ff9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.multioutput import MultiOutputClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import hamming_loss, jaccard_score, f1_score\n",
    "\n",
    "# # Load the data into a DataFrame\n",
    "# data = [...]  # Replace with your data\n",
    "# df = df_train.copy()\n",
    "\n",
    "# # Feature Engineering\n",
    "# X = df['Description']  # Feature: Description\n",
    "# y = df[['lvl1', 'lvl2', 'lvl3']]  # Targets: lvl1, lvl2, lvl3\n",
    "\n",
    "# # Convert Description to TF-IDF features\n",
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "# X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Model Selection and Training\n",
    "# models = []\n",
    "# for i in range(y.shape[1]):\n",
    "#     model = LogisticRegression()\n",
    "#     model.fit(X_train, y_train.iloc[:, i])\n",
    "#     models.append(model)\n",
    "\n",
    "# # Model Evaluation\n",
    "# y_pred = []\n",
    "# for model in models:\n",
    "#     y_pred.append(model.predict(X_test))\n",
    "\n",
    "# y_pred = pd.DataFrame(y_pred).T\n",
    "\n",
    "# print('Hamming Loss:', hamming_loss(y_test, y_pred))\n",
    "# print('Jaccard Score:', jaccard_score(y_test, y_pred, average='samples'))\n",
    "# print('F1 Score:', f1_score(y_test, y_pred, average='samples'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
